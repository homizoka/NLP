{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìò MODULE 2.1 : Les Outils du NLP (Spacy, NLTK, Pandas, Regex)\n",
    "\n",
    "**Objectif du TP :**\n",
    "Prendre en main les biblioth√®ques fondamentales. Comprendre la diff√©rence entre une cha√Æne de caract√®res (`String`) et un document trait√© (`Doc`).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è √âTAPE 1 : Installation\n",
    "Nous installons Spacy et t√©l√©chargeons le mod√®le de langue anglais (`en_core_web_sm`). C'est le \"cerveau\" qui contient la grammaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation de la librairie\n",
    "!pip install -U spacy\n",
    "\n",
    "# T√©l√©chargement du mod√®le (Small English)\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† √âTAPE 2 : Le Pipeline SpaCy\n",
    "Nous allons charger le mod√®le et transformer du texte brut en un objet intelligent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# 1. Chargement du mod√®le\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# 2. Traitement (Le texte passe dans le Pipeline : Tokenizer -> Tagger -> Parser -> NER)\n",
    "texte = \"Apple is looking at buying U.K. startup for $1 billion.\"\n",
    "doc = nlp(texte)\n",
    "\n",
    "print(\"Traitement termin√© !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des Tokens\n",
    "Regardons ce que Spacy a compris de notre phrase. Pour chaque mot, nous affichons :\n",
    "* **Text** : Le mot original.\n",
    "* **POS** (Part of Speech) : La nature grammaticale (Verbe, Nom...).\n",
    "* **Lemma** : La racine du mot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage sous forme de tableau\n",
    "print(f\"{'MOT':{12}} {'NATURE (POS)':{15}} {'RACINE (LEMMA)'}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for token in doc:\n",
    "    print(f\"{token.text:{12}} {token.pos_:{15}} {token.lemma_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üïµÔ∏è √âTAPE 3 : Reconnaissance d'Entit√©s (NER)\n",
    "Spacy a aussi d√©tect√© les noms propres automatiquement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Entit√©s d√©tect√©es :\")\n",
    "for ent in doc.ents:\n",
    "    # ent.label_ donne le type (ORG = Organisation, GPE = Pays/Lieu, MONEY = Argent)\n",
    "    print(f\" - {ent.text} ({ent.label_})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üêº √âTAPE 4 : Pandas et les Donn√©es\n",
    "Dans la vraie vie, on charge des fichiers Excel/CSV. Pandas est fait pour √ßa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cr√©ation d'un faux dataset\n",
    "data = {\n",
    "    \"Commentaire\": [\n",
    "        \"I love this product!\",\n",
    "        \"Worst service ever.\",\n",
    "        \"It is okay, not great.\"\n",
    "    ],\n",
    "    \"Note\": [5, 1, 3]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Appliquer SpaCy sur une colonne enti√®re\n",
    "# On compte le nombre de mots pour chaque commentaire\n",
    "df['Nb_Mots'] = df['Commentaire'].apply(lambda x: len(nlp(x)))\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç √âTAPE 5 : Regex pour le nettoyage\n",
    "Si on veut trouver quelque chose de pr√©cis (un email, une date) que l'IA rate parfois, on utilise Regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "texte_sale = \"Contactez support@google.com ou test.user@yahoo.fr pour info.\"\n",
    "\n",
    "# Motif pour trouver un email\n",
    "motif_email = r\"[\\w\\.-]+@[\\w\\.-]+\"\n",
    "\n",
    "emails = re.findall(motif_email, texte_sale)\n",
    "print(f\"Emails trouv√©s : {emails}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéì Exercice Final\n",
    "Analysez la phrase suivante avec SpaCy et extrayez les entit√©s nomm√©es :\n",
    "*\"Elon Musk bought Twitter in 2022.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Votre code ici\n",
    "phrase_exo = \"Elon Musk bought Twitter in 2022.\"\n",
    "\n",
    "# Indice : doc = nlp(phrase_exo)\n",
    "# Indice : bouclez sur doc.ents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
